<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>リアルタイム会話ダイアライゼーション</title>
    
    <!-- Google Fonts: Inter -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- 作成したCSSファイルを読み込み -->
    <link rel="stylesheet" href="styles.css">
</head>
<body>

    <div class="main-container">
        <!-- ヘッダー -->
        <div class="header">
            <h1>会話ダイアライザー</h1>
            <p>スピーカーを登録してから、マイクボタンを押して会話を開始してください。</p>
        </div>

        <!-- スピーカー登録セクション -->
        <div class="enrollment-section">
            <h2>スピーカー登録</h2>
            <div class="add-speaker-form">
                <input type="text" id="speakerNameInput" placeholder="スピーカーの名前を入力">
                <button id="addSpeakerButton" class="button primary">追加</button>
            </div>
            <div id="speakerList" class="speaker-list">
                <!-- スピーカープロファイルがここに表示されます -->
            </div>
             <p id="enrollmentStatus"></p>
        </div>

        <!-- 録音コントロールとステータス -->
        <div class="controls-container">
            <button id="recordButton" title="録音開始/停止">
                <!-- マイクアイコン -->
                <svg id="micIcon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"></path>
                    <path d="M17 11h-1c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92z"></path>
                </svg>
                 <!-- 停止アイコン (デフォルトで非表示) -->
                <svg id="stopIcon" class="hidden" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor">
                    <path d="M6 6h12v12H6z"></path>
                </svg>
            </button>
            <p id="status">録音準備完了</p>
        </div>
        
        <!-- 文字起こし表示エリア -->
        <div id="transcriptContainer" class="transcript-container">
            <!-- 文字起こしの結果がここに表示されます -->
        </div>
    </div>

    <!-- Azure Speech SDK -->
    <script src="https://aka.ms/csspeech/js/latest/speech-sdk.js"></script>

    <!-- アプリケーションのロジック -->
    <script type="module">
        // --- DOM要素の参照 ---
        const recordButton = document.getElementById('recordButton');
        const micIcon = document.getElementById('micIcon');
        const stopIcon = document.getElementById('stopIcon');
        const statusEl = document.getElementById('status');
        const transcriptContainer = document.getElementById('transcriptContainer');
        const speakerNameInput = document.getElementById('speakerNameInput');
        const addSpeakerButton = document.getElementById('addSpeakerButton');
        const speakerList = document.getElementById('speakerList');
        const enrollmentStatus = document.getElementById('enrollmentStatus');

        // --- アプリケーションの状態 ---
        let recognizer = null;
        let isRecording = false;
        let conversationData = new Map();
        let speakerProfiles = new Map(); // profileId をスピーカー名にマッピング
        let speakerOrder = []; // スピーカーの表示順を管理

        // --- Azureの認証情報 ---
        // Viteを使っていないため、これらの値は直接設定するか、
        // 安全な方法（サーバーから取得するなど）で読み込む必要があります。
        // ここではデモ用に仮の値を設定します。
        // 必ずVercelの環境変数で設定した実際の値に置き換えてください。
        const speechKey = "2EGwVWHaUbiKOCmoRVHtS9gkntofNcKpn97g8hTDrYHmGqYRWnq0JQQJ99BFACi0881XJ3w3AAAYACOGSP1t"; 
        const speechRegion = "japaneast";

        // Viteの`import.meta.env`は使えないので、直接グローバルスコープから参照
        if (!speechKey || !speechRegion || speechKey === "6EBCCkLWMiNWTx7zPypkvhhpaoY21nFt8Kdv51Ds1NBcQACCLX2uJQQJ99BFACi0881XJ3w3AAAYACOGSvBH") {
            updateStatus("japaneast", true);
            recordButton.disabled = true;
        }

        // --- スピーカープロファイル管理 ---
        
        addSpeakerButton.addEventListener('click', async () => {
            const name = speakerNameInput.value.trim();
            if (!name) {
                alert("名前を入力してください。");
                return;
            }
            addSpeakerButton.disabled = true;
            addSpeakerButton.innerHTML = '<div class="spinner"></div>';

            try {
                // サーバーレス関数を呼び出してプロファイルを作成
                const response = await fetch('/api/speaker-profiles', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ name: name })
                });

                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.error || 'サーバーでエラーが発生しました。');
                }
                
                const { profileId } = await response.json();
                speakerProfiles.set(profileId, { name: name, enrolled: false });
                speakerNameInput.value = '';
                renderSpeakerList();
            } catch (error) {
                console.error("スピーカーの追加エラー:", error);
                alert(`スピーカーの追加に失敗しました: ${error.message}`);
            } finally {
                 addSpeakerButton.disabled = false;
                 addSpeakerButton.textContent = '追加';
            }
        });

        function renderSpeakerList() {
            speakerList.innerHTML = '';
            for (const [profileId, profile] of speakerProfiles.entries()) {
                const div = document.createElement('div');
                div.className = 'speaker-item';
                div.innerHTML = `
                    <span>${profile.name}</span>
                    ${profile.enrolled 
                        ? '<span>登録済み</span>' 
                        : `<button data-profile-id="${profileId}" class="enroll-button button enroll">声を登録</button>`}
                `;
                speakerList.appendChild(div);
            }
        }

        speakerList.addEventListener('click', async (e) => {
            if (e.target.classList.contains('enroll-button')) {
                const button = e.target;
                const profileId = button.dataset.profileId;
                const speakerName = speakerProfiles.get(profileId).name;
                
                button.disabled = true;
                button.innerHTML = '<div class="spinner"></div>';
                enrollmentStatus.textContent = `「${speakerName}」さんを登録中...「Hey Cortana, what's the weather like?」と読み上げてください。`;
                
                try {
                    // 登録用に5秒間音声を録音
                    const audioBlob = await recordAudio(5000); 
                    
                    // サーバーレス関数に音声を送信して登録
                    const response = await fetch(`/api/speaker-profiles`, {
                        method: 'PUT',
                        headers: {
                            'Content-Type': 'application/octet-stream',
                            // `req.body`がストリームとして扱われるため、カスタムヘッダーでIDを渡す
                            'X-Profile-Id': profileId 
                        },
                        body: audioBlob
                    });

                    if (!response.ok) {
                        const error = await response.json();
                        throw new Error(error.error || "登録に失敗しました。");
                    }
                    
                    speakerProfiles.get(profileId).enrolled = true;
                    enrollmentStatus.textContent = `「${speakerName}」さんの登録が完了しました！`;
                    renderSpeakerList();

                } catch (error) {
                    console.error('登録失敗:', error);
                    enrollmentStatus.textContent = `登録に失敗しました: ${error.message}`;
                    // 失敗した場合はボタンを元に戻す
                    button.disabled = false;
                    button.textContent = '声を登録';
                }
            }
        });

        function recordAudio(duration) {
             return new Promise(async (resolve, reject) => {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    const mediaRecorder = new MediaRecorder(stream);
                    const audioChunks = [];

                    mediaRecorder.addEventListener("dataavailable", event => {
                        audioChunks.push(event.data);
                    });

                    const stop = () => {
                        if (mediaRecorder.state === "recording") {
                            mediaRecorder.stop();
                        }
                        stream.getTracks().forEach(track => track.stop());
                    };
                    
                    mediaRecorder.addEventListener("stop", () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        resolve(audioBlob);
                    });
                    
                    setTimeout(stop, duration);
                    mediaRecorder.start();
                } catch(err) {
                    reject(err);
                }
            });
        }


        // --- 主要なダイアライゼーションロジック ---

        async function startDiarization() {
            if (isRecording) return;
            
            updateUIVisuals(true);
            updateStatus("サービスに接続中...");

            const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(speechKey, speechRegion);
            speechConfig.speechRecognitionLanguage = "ja-JP"; // 日本語に設定

            const audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
            
            recognizer = new SpeechSDK.ConversationTranscriber(speechConfig, audioConfig);
            conversationData.clear();
            speakerOrder = [];
            transcriptContainer.innerHTML = '';
            
            // 登録済みのスピーカーからVoiceProfileを作成
            const enrolledProfiles = [];
            for(const [profileId, profile] of speakerProfiles.entries()){
                if(profile.enrolled){
                    const voiceProfile = SpeechSDK.VoiceProfile.fromSpeakerProfileId(profileId);
                    enrolledProfiles.push(voiceProfile);
                }
            }
            
            // 作成したVoiceProfileを認識エンジンに追加
            if (enrolledProfiles.length > 0) {
                const speakerIdentificationModel = SpeechSDK.SpeakerIdentificationModel.fromVoiceProfiles(enrolledProfiles);
                await recognizer.addSpeakerIdentificationModelAsync(speakerIdentificationModel);
            }


            recognizer.sessionStarted = (s, e) => updateStatus("マイクに向かって話してください...");
            recognizer.sessionStopped = (s, e) => {
                updateStatus("最終結果を処理中...");
                stopDiarization();
            };
            recognizer.canceled = (s, e) => {
                updateStatus(`キャンセルされました: ${e.errorDetails}`, true);
                stopDiarization();
            };
            
            recognizer.transcribed = (s, e) => {
                const result = e.result;
                if (result.reason === SpeechSDK.ResultReason.RecognizedSpeech && result.text) {
                    // profileIdからスピーカー名を取得
                    const profile = speakerProfiles.get(result.speakerId);
                    const speakerName = profile ? profile.name : `スピーカー ${result.speakerId}`;
                    
                    const utterance = { text: result.text, offset: result.offset };
                    
                    if (conversationData.has(speakerName)) {
                        conversationData.get(speakerName).push(utterance);
                    } else {
                        conversationData.set(speakerName, [utterance]);
                        speakerOrder.push(speakerName); // 新しいスピーカーを順序リストに追加
                    }
                    renderTranscript();
                }
            };

            recognizer.startTranscribingAsync(() => {}, (err) => {
                updateStatus(`エラー: ${err}`, true);
                stopDiarization();
            });
        }

        function stopDiarization() {
             if (!recognizer) return;
            
            recognizer.stopTranscribingAsync(
                () => {
                    recognizer.close();
                    recognizer = null;
                    updateUIVisuals(false);
                    updateStatus("録音を停止しました。最終的な文字起こし結果はこちらです。");
                },
                (err) => {
                    console.error("認識エンジンの停止エラー:", err);
                    updateUIVisuals(false);
                    updateStatus(`停止エラー: ${err}`, true);
                }
            );
        }

        function renderTranscript() {
            transcriptContainer.innerHTML = '';
            
            // 最初に話した人から順番に表示
            for (const speakerName of speakerOrder) {
                if (!conversationData.has(speakerName)) continue;

                const utterances = conversationData.get(speakerName);
                const combinedText = utterances.map(u => u.text).join(' ');

                // speakerOrderでのインデックスが偶数か奇数かで左右を決定
                const alignClass = speakerOrder.indexOf(speakerName) % 2 === 0 ? 'align-left' : 'align-right';

                const bubbleContainer = document.createElement('div');
                bubbleContainer.className = `speaker-bubble-container ${alignClass}`;

                bubbleContainer.innerHTML = `
                    <div class="speaker-bubble">
                        <p class="speaker-name">${speakerName}</p>
                        <p>${combinedText}</p>
                    </div>
                `;
                transcriptContainer.appendChild(bubbleContainer);
            }
            transcriptContainer.scrollTop = transcriptContainer.scrollHeight;
        }

        function updateUIVisuals(recording) {
            isRecording = recording;
            // CSSクラスの付け外しでスタイルを変更
            recordButton.classList.toggle('recording', recording);
            micIcon.classList.toggle('hidden', recording);
            stopIcon.classList.toggle('hidden', !recording);
        }

        function updateStatus(text, isError = false) {
            statusEl.textContent = text;
            statusEl.classList.toggle('error', isError);
        }

        // --- イベントリスナー ---
        recordButton.addEventListener('click', () => {
            if (!isRecording) {
                startDiarization();
            } else {
                stopDiarization();
            }
        });
        
        // --- 初期化 ---
        renderSpeakerList();
    </script>
</body>
</html>
